{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BeamOnColab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9982NiHmlog"
      },
      "source": [
        "# Data Engineer coding task\r\n",
        "Convert level 3 to level 1 data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKKEVJyLp_0z"
      },
      "source": [
        "# Why Beam? Beam=Batch+strEAM\r\n",
        "\r\n",
        "Apache Beam (https://beam.apache.org/): An advanced unified programming model\r\n",
        "\r\n",
        "Implement batch and streaming data processing jobs that run on any execution engine.\r\n",
        "\r\n",
        "Apache Beam supports distributed processing back-ends, which include Apache Flink, Apache Spark, and Google Cloud Dataflow.\r\n",
        "\r\n",
        "So that Apache Beam application can be deployed on Google Cloud Dataflow as a SERVERLESS solution.\r\n",
        "\r\n",
        "Also, Apache Beam batch application can work in Colab.\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Mvl11eFmyBz"
      },
      "source": [
        "# Batch implementation\r\n",
        "\r\n",
        "In order to provide a **Serverless** solution, this task was completed as a notebook. \r\n",
        "This notebook was developed and tested on Colab (https://colab.research.google.com/) along with an Apache Beam DirectRunner.\r\n",
        "\r\n",
        " <font color=red>Colab will raise some errors for the Apache beam installation. Please ignore them, which won't affect the following functions.</font> "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsjNKX11nVip",
        "outputId": "b87fd62d-f217-4a2a-ceda-8616f5b5a7bd"
      },
      "source": [
        "# Run and print a shell command.\r\n",
        "def run(cmd):\r\n",
        "  print('>> {}'.format(cmd))\r\n",
        "  !{cmd}\r\n",
        "  print('')\r\n",
        "\r\n",
        "# Install apache-beam.\r\n",
        "run('pip install --quiet apache-beam')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">> pip install --quiet apache-beam\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sh2c91HFpD1j"
      },
      "source": [
        "## Data Source\r\n",
        "\r\n",
        "The original data was upload to Google Cloud Storage in advance, which saves time to provide data.\r\n",
        "\r\n",
        "We are to download the data to the local."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UciiAE_TmggJ",
        "outputId": "4823139a-5942-4ec6-dadf-e6a11300fb50"
      },
      "source": [
        "run('gsutil cp gs://level3-to-level1-data/market_data_v2.csv .')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">> gsutil cp gs://level3-to-level1-data/market_data_v2.csv .\n",
            "Copying gs://level3-to-level1-data/market_data_v2.csv...\n",
            "- [1 files][  2.6 MiB/  2.6 MiB]                                                \n",
            "Operation completed over 1 objects/2.6 MiB.                                      \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwF8sSIytsYA",
        "outputId": "7874a630-b7e6-4acd-f9c5-ba32dabaea57"
      },
      "source": [
        "!ls -l"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 4680\n",
            "-rw-r--r-- 1 root root 2026912 Dec 13 09:38 L1_market_data-00000-of-00001.csv\n",
            "-rw-r--r-- 1 root root 2757472 Dec 13 14:00 market_data_v2.csv\n",
            "drwxr-xr-x 1 root root    4096 Dec  2 22:04 sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZJqj4HBqHTW"
      },
      "source": [
        "## The Primary Process Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLluP_KSqUdd"
      },
      "source": [
        "#!/usr/bin/python\r\n",
        "# -*- coding: utf-8 -*-\r\n",
        "import sys\r\n",
        "\r\n",
        "def toFloat_Or_0(s):\r\n",
        "    try:\r\n",
        "        return float(s)\r\n",
        "    except:\r\n",
        "        return 0\r\n",
        "\r\n",
        "def ToInt_Or_0(s):\r\n",
        "    try:\r\n",
        "        return int(s)\r\n",
        "    except:\r\n",
        "        return 0\r\n",
        "\r\n",
        "def float2str(s):\r\n",
        "    if s >= sys.maxsize:\r\n",
        "        return ''\r\n",
        "    else:\r\n",
        "        return '{:.3f}'.format(s)\r\n",
        "\r\n",
        "def int2str(s):\r\n",
        "    return str(s)\r\n",
        "\r\n",
        "g_init_HOST = ''\r\n",
        "g_orders = {}  # (OrderId, side): (qty, price)\r\n",
        "g_priceQty_bid = {} # {price:quantity}\r\n",
        "g_priceQty_ask = {} # {price:quantity}\r\n",
        "g_bid_price = 0\r\n",
        "g_ask_price = sys.maxsize\r\n",
        "g_bid_size = 0\r\n",
        "g_ask_size = 0\r\n",
        "max_orders = 0 # for performance metrics\r\n",
        "def upsertPxQty_bid(price, delta): \r\n",
        "    \"\"\" Update or Insert bid price-quantity dictionary\r\n",
        "    delta is the quantity to change\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    #global g_init_HOST\r\n",
        "    #global g_inited\r\n",
        "    #global g_orders\r\n",
        "    global g_priceQty_bid\r\n",
        "    #global g_priceQty_ask\r\n",
        "    global g_bid_price\r\n",
        "    #global g_ask_price\r\n",
        "    global g_bid_size\r\n",
        "    #global g_ask_size\r\n",
        "\r\n",
        "    if price in g_priceQty_bid:  # existing price\r\n",
        "        qty = g_priceQty_bid[price]\r\n",
        "        if qty + delta == 0:  # price was closed\r\n",
        "            del g_priceQty_bid[price]\r\n",
        "\r\n",
        "            if len(g_priceQty_bid) > 0:\r\n",
        "                g_bid_price = max(g_priceQty_bid.keys())\r\n",
        "                g_bid_size = g_priceQty_bid[g_bid_price]\r\n",
        "            else: # no bids\r\n",
        "                g_bid_price = 0\r\n",
        "                g_bid_size = 0\r\n",
        "        else:\r\n",
        "            g_priceQty_bid[price] = qty + delta\r\n",
        "            if price >= g_bid_price:\r\n",
        "                g_bid_price = price\r\n",
        "                g_bid_size = qty + delta\r\n",
        "    else: # new price\r\n",
        "        g_priceQty_bid[price] = delta\r\n",
        "\r\n",
        "        if price > g_bid_price:  # higher bid price\r\n",
        "            g_bid_price = price\r\n",
        "            g_bid_size = max(delta, 0)\r\n",
        "    return\r\n",
        "\r\n",
        "def upsertPxQty_ask(price, delta):  \r\n",
        "    \"\"\" Update or Insert ask price-quantity dictionary\r\n",
        "    delta is the quantity to change\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    #global g_init_HOST\r\n",
        "    #global g_inited\r\n",
        "    #global g_orders\r\n",
        "    #global g_priceQty_bid\r\n",
        "    global g_priceQty_ask\r\n",
        "    #global g_bid_price\r\n",
        "    global g_ask_price\r\n",
        "    #global g_bid_size\r\n",
        "    global g_ask_size\r\n",
        "\r\n",
        "    if price in g_priceQty_ask:  # existing price\r\n",
        "        qty = g_priceQty_ask[price]\r\n",
        "        if qty + delta == 0:  # price was closed\r\n",
        "            del g_priceQty_ask[price]\r\n",
        "\r\n",
        "            if len(g_priceQty_ask) > 0:\r\n",
        "                g_ask_price = min(g_priceQty_ask.keys())\r\n",
        "                g_ask_size = g_priceQty_ask[g_ask_price]\r\n",
        "            else:  # no asks\r\n",
        "                g_ask_price = sys.maxsize\r\n",
        "                g_ask_size = 0\r\n",
        "        else:\r\n",
        "            g_priceQty_ask[price] = qty + delta\r\n",
        "            if price <= g_ask_price:\r\n",
        "                g_ask_price = price\r\n",
        "                g_ask_size = qty + delta\r\n",
        "    else:        # new price\r\n",
        "        g_priceQty_ask[price] = delta\r\n",
        "\r\n",
        "        if price < g_ask_price:  # lower ask price\r\n",
        "            g_ask_price = price\r\n",
        "            g_ask_size = max(delta, 0)\r\n",
        "    return\r\n",
        "\r\n",
        "def delOrd(OrderId, side):  \r\n",
        "    \"\"\" To delete an order from the order book\r\n",
        "    There are 2 situations:\r\n",
        "      1.  An order is cancelled \r\n",
        "      2.  An order is filled\r\n",
        "    \"\"\"\r\n",
        "    \r\n",
        "    global g_init_HOST\r\n",
        "    global g_inited\r\n",
        "    global g_orders\r\n",
        "    #global g_priceQty_bid\r\n",
        "    #global g_priceQty_ask\r\n",
        "    # global g_bid_price\r\n",
        "    # global g_ask_price\r\n",
        "    # global g_bid_size\r\n",
        "    # global g_ask_size\r\n",
        "\r\n",
        "    if not (OrderId, side) in g_orders:\r\n",
        "        return\r\n",
        "\r\n",
        "    (qty, px) = g_orders[(OrderId, side)]\r\n",
        "\r\n",
        "    del g_orders[(OrderId, side)]\r\n",
        "\r\n",
        "    if side == 'BUY':\r\n",
        "        upsertPxQty_bid(px, -qty)\r\n",
        "    else:\r\n",
        "        upsertPxQty_ask(px, -qty)\r\n",
        "          \r\n",
        "    return\r\n",
        "\r\n",
        "def upsertOrd(OrderId,side,quantity,price):\r\n",
        "    \"\"\" To update or insert an order\r\n",
        "    There are 2 situations:\r\n",
        "      1.  An order is added \r\n",
        "      2.  An order is updated\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    global g_init_HOST\r\n",
        "    global g_inited\r\n",
        "    global g_orders\r\n",
        "    global g_priceQty_bid\r\n",
        "    global g_priceQty_ask\r\n",
        "\r\n",
        "  # global g_bid_price\r\n",
        "  # global g_ask_price\r\n",
        "  # global g_bid_size\r\n",
        "  # global g_ask_size\r\n",
        "\r\n",
        "    delta = 0  #   quantity change\r\n",
        "    if (OrderId, side) in g_orders:\r\n",
        "        (qty, px) = g_orders[(OrderId, side)]\r\n",
        "        delta = quantity - qty\r\n",
        "    else:\r\n",
        "        delta = quantity\r\n",
        "\r\n",
        "    if side == 'BUY':\r\n",
        "        upsertPxQty_bid(price, delta)\r\n",
        "    else:\r\n",
        "        upsertPxQty_ask(price, delta)\r\n",
        "\r\n",
        "    g_orders[(OrderId, side)] = (quantity, price)\r\n",
        "\r\n",
        "def tradeOrd(OrderId, side, quantity):\r\n",
        "    \"\"\" To fill an order\r\n",
        "    We will ignore the fill of market orders\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    global g_init_HOST\r\n",
        "    global g_inited\r\n",
        "    global g_orders\r\n",
        "    global g_priceQty_bid\r\n",
        "    global g_priceQty_ask\r\n",
        "\r\n",
        "  # global g_bid_price\r\n",
        "  # global g_ask_price\r\n",
        "  # global g_bid_size\r\n",
        "  # global g_ask_size\r\n",
        "\r\n",
        "    if (OrderId, side) in g_orders:\r\n",
        "        (qty, px) = g_orders[(OrderId, side)]\r\n",
        "        qty = qty - quantity  # Trade instead of add order\r\n",
        "        if quantity == 0:  #  0\r\n",
        "            delOrd(OrderId, side)\r\n",
        "            return   # in case duplicate process\r\n",
        "        else:\r\n",
        "            g_orders[(OrderId, side)] = (qty, px)\r\n",
        "            if side == 'BUY':\r\n",
        "                upsertPxQty_bid(px, -quantity)\r\n",
        "            else:\r\n",
        "                upsertPxQty_ask(px, -quantity)\r\n",
        "            return\r\n",
        "    else:\r\n",
        "        return   # for market orders\r\n",
        "def processOneMsg(element):\r\n",
        "    \"\"\" To process one streaming message or a row of record\r\n",
        "    There are some special situations:\r\n",
        "    1. To initialize the order book\r\n",
        "    2. To ignore market orders\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    global g_init_HOST\r\n",
        "    global g_inited\r\n",
        "    global g_orders\r\n",
        "    #global g_priceQty_bid\r\n",
        "    #global g_priceQty_ask\r\n",
        "    global g_bid_price\r\n",
        "    global g_ask_price\r\n",
        "    global g_bid_size\r\n",
        "    global g_ask_size\r\n",
        "\r\n",
        "    # This is very important for in streaming mode a message could be in bytes\r\n",
        "    if (type(element) != str):\r\n",
        "      element=element.decode('utf-8')\r\n",
        "    \r\n",
        "    if element.startswith(\"HOST\"): # To deal with the CSV header\r\n",
        "      return [\"time,bid_price,ask_price,bid_size,ask_size,seq_num\"]\r\n",
        "\r\n",
        "    (HOST,\r\n",
        "        seq_num,\r\n",
        "        is_image,\r\n",
        "        add_orderid,\r\n",
        "        add_side,\r\n",
        "        add_price,\r\n",
        "        add_qty,\r\n",
        "        add_position,\r\n",
        "        update_orderid,\r\n",
        "        update_side,\r\n",
        "        update_price,\r\n",
        "        update_qty,\r\n",
        "        update_position,\r\n",
        "        delete_orderid,\r\n",
        "        delete_side,\r\n",
        "        trade_orderid,\r\n",
        "        trade_side,\r\n",
        "        trade_qty,\r\n",
        "        trade_price,) = element.split(',')\r\n",
        "\r\n",
        "    HOST = HOST\r\n",
        "    seq_num = seq_num\r\n",
        "    is_image = bool(is_image)\r\n",
        "    add_orderid = add_orderid\r\n",
        "    add_side = add_side\r\n",
        "    add_price = toFloat_Or_0(add_price)\r\n",
        "    add_qty = ToInt_Or_0(add_qty)\r\n",
        "    add_position = ToInt_Or_0(add_position)\r\n",
        "    update_orderid = update_orderid\r\n",
        "    update_side = update_side\r\n",
        "    update_price = toFloat_Or_0(update_price)\r\n",
        "    update_qty = ToInt_Or_0(update_qty)\r\n",
        "    update_position = ToInt_Or_0(update_position)\r\n",
        "    delete_orderid = delete_orderid\r\n",
        "    delete_side = delete_side\r\n",
        "    trade_orderid = trade_orderid\r\n",
        "    trade_side = trade_side\r\n",
        "    trade_qty = ToInt_Or_0(trade_qty)\r\n",
        "    trade_price = toFloat_Or_0(trade_price)\r\n",
        "\r\n",
        "    if is_image:\r\n",
        "        if HOST != g_init_HOST:  \r\n",
        "            # To initialize the order book\r\n",
        "            g_init_HOST = HOST\r\n",
        "            g_orders = {}\r\n",
        "            g_bid_price = 0\r\n",
        "            g_ask_price = sys.maxsize\r\n",
        "            g_bid_size = 0\r\n",
        "            g_ask_size = 0\r\n",
        "\r\n",
        "    if delete_orderid != '':  # Process DELETE\r\n",
        "        delOrd(delete_orderid, delete_side)\r\n",
        "    elif add_orderid != '': # Process ADD\r\n",
        "        if add_price > 0 and add_price < 1e+308:\r\n",
        "            upsertOrd(add_orderid, add_side, add_qty, add_price)\r\n",
        "    elif update_orderid != '': # Process UPDATE\r\n",
        "        if update_price > 0 and update_price < 1e+308:\r\n",
        "            upsertOrd(update_orderid, update_side, update_qty, update_price)\r\n",
        "    elif trade_orderid != '': # Process TRADE\r\n",
        "        tradeOrd(trade_orderid, trade_side, trade_qty)\r\n",
        "\r\n",
        "    global max_orders\r\n",
        "    max_orders = (len(g_orders) if len(g_orders) > max_orders else 0) \r\n",
        "\r\n",
        "    result = [HOST,\r\n",
        "        float2str(g_bid_price),\r\n",
        "        float2str(g_ask_price),\r\n",
        "        int2str(g_bid_size),\r\n",
        "        int2str(g_ask_size),\r\n",
        "        seq_num,]\r\n",
        "\r\n",
        "    return [','.join(result) ] #For some environment, we have to add '\\n'"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5c4ujG36rNXK"
      },
      "source": [
        "## The Apache Beam ParDo wrapper"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4b07-fFtjnN"
      },
      "source": [
        "import apache_beam as beam\r\n",
        "\r\n",
        "class OneRowParDo(beam.DoFn):\r\n",
        "    def process(self, element):\r\n",
        "      return processOneMsg(element)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G90bygb6qVBy"
      },
      "source": [
        "## The Beam Pipeline for batch, actually from an CSV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tjl-SS6qnbj"
      },
      "source": [
        "streamingMode=False\r\n",
        "pubSubTopic=\"projects/grasshopper-298307/topics/L3toL1\"\r\n",
        "\r\n",
        "def run_pipeline():\r\n",
        "    if streamingMode:\r\n",
        "        options = PipelineOptions(args, save_main_session=True, streaming=True)\r\n",
        "    else:\r\n",
        "        options = beam.options.pipeline_options.PipelineOptions(streaming=False)\r\n",
        "\r\n",
        "    p = beam.Pipeline(options=options)\r\n",
        "\r\n",
        "    if streamingMode:\r\n",
        "      read = (\r\n",
        "          p \r\n",
        "          | 'Read from PubSub '>> beam.io.ReadFromPubSub(topic=pubSubTopic)\r\n",
        "      )\r\n",
        "    else:\r\n",
        "      read = (\r\n",
        "          p \r\n",
        "          | 'Reads from csv' >> beam.io.ReadFromText('market_data_v2.csv') \r\n",
        "      )\r\n",
        "    process= (\r\n",
        "        read \r\n",
        "        | 'Structures data' >> beam.ParDo(OneRowParDo())\r\n",
        "        | 'Save L1 data into a file' >> beam.io.WriteToText('L1_market_data',file_name_suffix=\".csv\")\r\n",
        "    )\r\n",
        "    \r\n",
        "    result = p.run()\r\n",
        "    result.wait_until_finish()  # For it to hold the terminal until it finishes\r\n",
        "\r\n",
        "run_pipeline()"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMpnUtBSGRB7"
      },
      "source": [
        "## The generated L1 data has been validated with expected_L1_market_data.csv\r\n",
        "\r\n",
        "For any matched row, the rest of columns carry the same values as the expected file.\r\n",
        "\r\n",
        "You may download the generated data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_kRim40GODL",
        "outputId": "eccf731e-6834-4ac1-df68-e883ca66f335"
      },
      "source": [
        "!ls -l"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 4680\n",
            "-rw-r--r-- 1 root root 2026912 Dec 13 14:00 L1_market_data-00000-of-00001.csv\n",
            "-rw-r--r-- 1 root root 2757472 Dec 13 14:00 market_data_v2.csv\n",
            "drwxr-xr-x 1 root root    4096 Dec  2 22:04 sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPLTw-aiqooG"
      },
      "source": [
        "# Streaming Implementation\r\n",
        "\r\n",
        "The same code in an independent file, Streaming.py, can be run in streaming mode. The code supports Google PubSub as streaming source.\r\n",
        "\r\n",
        "The streaming implementation is tested on Google Cloud Dataflow platform.\r\n",
        "\r\n",
        "The Google cloud environment will cost a few dollars."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMR9MJZXz2m9"
      },
      "source": [
        "## The Beam environment \r\n",
        "\r\n",
        "The Beam environment can be set up by following this tutorial (https://console.cloud.google.com/getting-started?walkthrough_tutorial_id=python_dataflow_quickstart&_ga=2.25278013.1291490325.1607857566-321077206.1587778923 )\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gog8AX_w0HR4"
      },
      "source": [
        "## The streaming source\r\n",
        "The stream source can be simulated by a Google Dataflow template, Text Files on Cloud Storage to Pub/Sub (Stream) (https://cloud.google.com/dataflow/docs/guides/templates/provided-streaming#gcstexttocloudpubsubstream ) \r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RubOLlwEmYJ"
      },
      "source": [
        "## Command to run\r\n",
        "\r\n",
        "After configuration, such as streamingMode, topic name, access control, just use the following command to run:\r\n",
        "\r\n",
        "**python3 Streaming.py**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4d5bplMqyXT"
      },
      "source": [
        "# Things to consider"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSaOBcwB14sl"
      },
      "source": [
        "## How would you deal with data which arrive out of order?\r\n",
        "\r\n",
        "So far, the implement code only considers basic fault tolerance, such as bid/ask size cannot be negative, even an order size could be negative in the situation of outing of order.\r\n",
        "\r\n",
        "For serious situation of outing of order, the data can be recorded and replyed. In order to save cost, the history can be replayed PER order.\r\n",
        "\r\n",
        "In the streaming mode, some source, such as Google PubSub, can be polled to replay the history.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQxDLPkoDKpk"
      },
      "source": [
        "## Bonus points for a streaming implementation.\r\n",
        "\r\n",
        "Implemented in an independent file, Streaming.py."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kahJ6rK_DZjB"
      },
      "source": [
        "## How might it be possible for a unified batch and streaming implementation to work?\r\n",
        "\r\n",
        "Apache Beam is the perfect platform."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gaxLoQTAEFxc"
      },
      "source": [
        "# Implementation Discussion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKt8GUrCET12"
      },
      "source": [
        "## Architecture\r\n",
        "\r\n",
        "Due to the shared order book in the memory, the implementation is not scalable. \r\n",
        "\r\n",
        "Even a STATEFUL Apache Beam doesn't provide the scalability.\r\n",
        "\r\n",
        "In order to be scalable, the shared order book should be put into an external persistent data base, such as Google BigTable.\r\n",
        "\r\n",
        "It depends on the business requirement. If one node can deal with the data in time and the history can be quickly replayed to rebuid the order book. One node model can be accepted. \r\n"
      ]
    }
  ]
}